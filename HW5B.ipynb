{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSeOGJRQFgrpbYdfrsnQ4B"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Simple Sampling**\n",
        "\n",
        "You are not allowed to use sampling libraries/functions. But you can use rand() call to generate a pseudo-uniform value in [0,1]; you can also use a library that computes the pdf(x|params). make sure to recap first Rejection Sampling and Inverse Transform Sampling\n",
        "\n",
        "A. Implement simple sampling from continuous distributions: uniform (min, max, sample_size) and gaussian (mu, sigma, sample_size)\n",
        "\n",
        "B. Implement sampling from a 2-dim Gaussian Distribution (2d mu, 2d sigma, sample_size)\n",
        "\n",
        "C. Implement wihtout-replacement sampling from a discrete non-uniform distribution (given as input) following the Steven's method described in class ( paper ). Test it on desired sample sizes N significantly smaller than population size M (for example N=20 M=300)"
      ],
      "metadata": {
        "id": "43pzv3vwOKF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h4E6bFvBK9oW",
        "outputId": "21404ea2-3e07-409d-aff4-78ecd110ebbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniform samples: [6.987538055619814, 2.6119309767933196, 9.453894979763586, 9.007527242424382, 2.542066158250824]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def sample_uniform(a, b, sample_size):\n",
        "    \"\"\"\n",
        "    Generates samples from a Uniform(a, b) distribution.\n",
        "\n",
        "    Args:\n",
        "        a (float): Lower bound.\n",
        "        b (float): Upper bound.\n",
        "        sample_size (int): Number of samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        list of float: Uniform samples.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    for _ in range(sample_size):\n",
        "        u = random.random()  # rand() returns value in [0,1)\n",
        "        sample = a + (b - a) * u\n",
        "        samples.append(sample)\n",
        "    return samples\n",
        "\n",
        "# Example usage:\n",
        "print(\"Uniform samples:\", sample_uniform(0, 10, 5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def sample_gaussian(mu, sigma, sample_size):\n",
        "    \"\"\"\n",
        "    Generates samples from a Gaussian distribution N(mu, sigma^2)\n",
        "    using the Box-Muller transform.\n",
        "\n",
        "    Args:\n",
        "        mu (float): Mean.\n",
        "        sigma (float): Standard deviation.\n",
        "        sample_size (int): Number of samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        list of float: Gaussian samples.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    # Process two samples per iteration using Box-Muller:\n",
        "    for _ in range(sample_size // 2):\n",
        "        u1 = random.random()\n",
        "        u2 = random.random()\n",
        "        # Avoid taking log of zero:\n",
        "        if u1 == 0:\n",
        "            u1 = 1e-10\n",
        "        z0 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
        "        z1 = math.sqrt(-2 * math.log(u1)) * math.sin(2 * math.pi * u2)\n",
        "        samples.append(mu + sigma * z0)\n",
        "        samples.append(mu + sigma * z1)\n",
        "    # If sample_size is odd, generate one additional sample:\n",
        "    if sample_size % 2 != 0:\n",
        "        u1 = random.random()\n",
        "        u2 = random.random()\n",
        "        if u1 == 0:\n",
        "            u1 = 1e-10\n",
        "        z0 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
        "        samples.append(mu + sigma * z0)\n",
        "    return samples\n",
        "\n",
        "# Example usage:\n",
        "print(\"Gaussian samples:\", sample_gaussian(0, 1, 5))"
      ],
      "metadata": {
        "id": "TpUYVB9AURMn",
        "outputId": "a1c2d934-823a-4747-807a-66efc63a56a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian samples: [-1.2823551358522043, -0.3916149557147224, 2.0250496247006513, -1.0520974229953688, -0.5949501315390834]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_gaussian_2d(mu_vector, sigma_vector, sample_size):\n",
        "    \"\"\"\n",
        "    Generates samples from a 2D Gaussian distribution with independent components.\n",
        "\n",
        "    Args:\n",
        "        mu_vector (list or tuple of floats): [mu_x, mu_y].\n",
        "        sigma_vector (list or tuple of floats): [sigma_x, sigma_y].\n",
        "        sample_size (int): Number of 2D samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        list of [float, float]: List of 2D sample points.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "\n",
        "    # For each sample, generate 2 independent standard normal numbers:\n",
        "    for _ in range(sample_size):\n",
        "        # We can use the Box-Muller transform to generate a pair; here we only need 2 numbers.\n",
        "        u1 = random.random()\n",
        "        u2 = random.random()\n",
        "        if u1 == 0:\n",
        "            u1 = 1e-10\n",
        "        z1 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
        "        # For the second normal, either call Box-Muller again or use the orthogonal value:\n",
        "        # For clarity, generate a new pair for each sample\n",
        "        u3 = random.random()\n",
        "        u4 = random.random()\n",
        "        if u3 == 0:\n",
        "            u3 = 1e-10\n",
        "        z2 = math.sqrt(-2 * math.log(u3)) * math.cos(2 * math.pi * u4)\n",
        "\n",
        "        # Transform to the desired mean and standard deviation:\n",
        "        sample_x = mu_vector[0] + sigma_vector[0] * z1\n",
        "        sample_y = mu_vector[1] + sigma_vector[1] * z2\n",
        "        samples.append([sample_x, sample_y])\n",
        "\n",
        "    return samples\n",
        "\n",
        "# Example usage:\n",
        "mu_2d = [0, 0]\n",
        "sigma_2d = [1, 1]\n",
        "print(\"2D Gaussian samples:\", sample_gaussian_2d(mu_2d, sigma_2d, 5))"
      ],
      "metadata": {
        "id": "nJTdiSsWUWyW",
        "outputId": "e5360d5a-3493-4365-f642-48512a7dca93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D Gaussian samples: [[-0.962700359874964, -0.6487905857268136], [-0.8560819786230847, -0.34007792571958795], [0.9278813267525409, 1.4630738821801952], [-0.5644163262626185, -0.8470550936827791], [0.5868602180560467, 1.3332663475644468]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_sample_without_replacement(weights, sample_size):\n",
        "    \"\"\"\n",
        "    Samples indices without replacement from a list of weights using\n",
        "    the method based on exponential variates (often called Steven's method).\n",
        "\n",
        "    Args:\n",
        "        weights (list of floats): Non-negative weights for the population (length M).\n",
        "        sample_size (int): Number of items to sample (N), N << M.\n",
        "\n",
        "    Returns:\n",
        "        list of int: Selected indices (without replacement).\n",
        "    \"\"\"\n",
        "    keys = []\n",
        "    # Compute a key for every element.\n",
        "    for i, w in enumerate(weights):\n",
        "        # To avoid division by zero, handle zero-weight items appropriately.\n",
        "        # Here we simply assign an infinite key so they will not be selected.\n",
        "        if w <= 0:\n",
        "            key = float('inf')\n",
        "        else:\n",
        "            u = random.random()  # Uniform in [0,1)\n",
        "            # To avoid log(0) in the extremely unlikely event u==0:\n",
        "            if u == 0:\n",
        "                u = 1e-10\n",
        "            key = -math.log(u) / w\n",
        "        keys.append((key, i))\n",
        "\n",
        "    # Sort items by their keys (ascending order) and select the sample_size smallest keys.\n",
        "    keys.sort(key=lambda x: x[0])\n",
        "    selected_indices = [index for (_, index) in keys[:sample_size]]\n",
        "    return selected_indices\n",
        "\n",
        "# Test scenario: N=20, M=300. We generate a synthetic weight vector.\n",
        "M = 300\n",
        "N = 20\n",
        "# For example, let the weights be random positive numbers (not necessarily summing to 1)\n",
        "population_weights = [random.random() + 0.1 for _ in range(M)]  # adding 0.1 to avoid zero weights\n",
        "\n",
        "selected = weighted_sample_without_replacement(population_weights, N)\n",
        "print(\"Selected indices (without replacement):\", selected)"
      ],
      "metadata": {
        "id": "nz7e72YXUtYA",
        "outputId": "26020e27-d487-4860-9c46-2fa5563a7d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected indices (without replacement): [8, 176, 62, 224, 77, 177, 18, 13, 58, 136, 74, 86, 0, 111, 126, 263, 46, 145, 44, 188]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2: Conditional Sampling**\n",
        "\n",
        "Implement Gibbs Sampling for a multidim gaussian generative joint, by using the conditionals which are also gaussian distributions . The minimum requirement is for joint to have D=2 variables and for Gibbs to alternate between the two."
      ],
      "metadata": {
        "id": "5-6pzvRXU9vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def sample_gaussian_value(mu, sigma):\n",
        "    \"\"\"\n",
        "    Generate a single sample from a Gaussian distribution N(mu, sigma^2)\n",
        "    using the Box–Muller transform.\n",
        "    \"\"\"\n",
        "    u1 = random.random()\n",
        "    u2 = random.random()\n",
        "    # Guard against zero for u1 (extremely unlikely)\n",
        "    if u1 == 0:\n",
        "        u1 = 1e-10\n",
        "    z = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
        "    return mu + sigma * z\n",
        "\n",
        "def gibbs_sampling_2d(mu, sigma, rho, num_samples, burn_in=100):\n",
        "    \"\"\"\n",
        "    Perform Gibbs sampling for a 2-dimensional Gaussian distribution.\n",
        "\n",
        "    The joint distribution:\n",
        "         (X, Y) ~ N( [mu_x, mu_y], Σ )\n",
        "    where Σ is defined as:\n",
        "         [sigma_x^2        rho*sigma_x*sigma_y]\n",
        "         [rho*sigma_x*sigma_y   sigma_y^2     ]\n",
        "\n",
        "    The conditionals are:\n",
        "      X|Y=y ~ N(mu_x + rho*(sigma_x/sigma_y)*(y-mu_y), (1-rho^2)*sigma_x^2)\n",
        "      Y|X=x ~ N(mu_y + rho*(sigma_y/sigma_x)*(x-mu_x), (1-rho^2)*sigma_y^2)\n",
        "\n",
        "    Args:\n",
        "        mu: list or tuple of two floats [mu_x, mu_y]\n",
        "        sigma: list or tuple of two floats [sigma_x, sigma_y]\n",
        "        rho: float, correlation coefficient between X and Y, must be in (-1, 1)\n",
        "        num_samples: int, number of samples to collect (after burn-in)\n",
        "        burn_in: int, number of burn-in iterations (default is 100)\n",
        "\n",
        "    Returns:\n",
        "        List of [x, y] samples from the joint distribution.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the chain. We can start at the mean.\n",
        "    x = mu[0]\n",
        "    y = mu[1]\n",
        "\n",
        "    samples = []\n",
        "\n",
        "    # Total iterations: burn_in + actual samples\n",
        "    total_iterations = burn_in + num_samples\n",
        "\n",
        "    for iteration in range(total_iterations):\n",
        "        # Sample X given current Y:\n",
        "        mean_x_cond = mu[0] + rho * (sigma[0]/sigma[1]) * (y - mu[1])\n",
        "        var_x_cond = (1 - rho**2) * sigma[0]**2\n",
        "        x = sample_gaussian_value(mean_x_cond, math.sqrt(var_x_cond))\n",
        "\n",
        "        # Sample Y given updated X:\n",
        "        mean_y_cond = mu[1] + rho * (sigma[1]/sigma[0]) * (x - mu[0])\n",
        "        var_y_cond = (1 - rho**2) * sigma[1]**2\n",
        "        y = sample_gaussian_value(mean_y_cond, math.sqrt(var_y_cond))\n",
        "\n",
        "        # After burn_in, collect the sample.\n",
        "        if iteration >= burn_in:\n",
        "            samples.append([x, y])\n",
        "\n",
        "    return samples\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Parameters for the joint Gaussian:\n",
        "mu = [0.0, 0.0]\n",
        "sigma = [1.0, 1.0]  # Standard deviations for X and Y\n",
        "rho = 0.8           # Correlation coefficient\n",
        "\n",
        "# Number of samples we want to collect (after burn-in)\n",
        "num_samples = 1000\n",
        "burn_in = 200\n",
        "\n",
        "# Run Gibbs Sampling\n",
        "samples = gibbs_sampling_2d(mu, sigma, rho, num_samples, burn_in)\n",
        "\n",
        "# Print a few samples to check\n",
        "for i, sample in enumerate(samples[:10]):\n",
        "    print(f\"Sample {i+1}: X = {sample[0]:.4f}, Y = {sample[1]:.4f}\")"
      ],
      "metadata": {
        "id": "fuIFyzb-U_s9",
        "outputId": "2553aaf9-9d18-4962-b1ab-0fa0af5f4516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: X = 0.6713, Y = 0.5571\n",
            "Sample 2: X = 0.1021, Y = 1.5488\n",
            "Sample 3: X = 0.8961, Y = 0.3792\n",
            "Sample 4: X = -0.2160, Y = 0.2510\n",
            "Sample 5: X = -0.9930, Y = 0.7896\n",
            "Sample 6: X = 1.0555, Y = 0.2000\n",
            "Sample 7: X = -0.0766, Y = 0.5402\n",
            "Sample 8: X = 0.0592, Y = 0.6796\n",
            "Sample 9: X = 0.4553, Y = 0.7211\n",
            "Sample 10: X = 0.1736, Y = -0.7669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3: Implement your own baby-LDA**\n",
        "\n",
        "Implement your own LDA using Gibbs Sampling, following this paper and this easy-to-read book . Gibbs Sampling is a lot slower than EM alternatives, so this can take some time; use a smaller sample of docs/words at first.\n",
        "\n",
        "20NG train dataset 11280 docs x 53000 words\n",
        "Small sonnet dataset (one per line) 154 docs x 3092 words"
      ],
      "metadata": {
        "id": "p9U6pXmlbOf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def discrete_sample(probabilities):\n",
        "    \"\"\"\n",
        "    Sample an index from a discrete distribution given by a list\n",
        "    of nonnegative (unnormalized) probabilities.\n",
        "    \"\"\"\n",
        "    total = sum(probabilities)\n",
        "    r = random.uniform(0, total)\n",
        "    cumulative = 0.0\n",
        "    for i, p in enumerate(probabilities):\n",
        "        cumulative += p\n",
        "        if cumulative >= r:\n",
        "            return i\n",
        "    return len(probabilities) - 1  # fallback\n",
        "\n",
        "def baby_lda(DOCS, Vocab, K, alpha, beta, iterations):\n",
        "    \"\"\"\n",
        "    A simple LDA implementation using Gibbs sampling.\n",
        "\n",
        "    Parameters:\n",
        "      DOCS: List of documents; each document is a list of word indices (integers) in [0, W-1].\n",
        "      Vocab: List of strings; the vocabulary of size W.\n",
        "      K: int; number of topics.\n",
        "      alpha: float; hyperparameter for the document-topic Dirichlet prior.\n",
        "      beta: float; hyperparameter for the topic-word Dirichlet prior.\n",
        "      iterations: int; number of Gibbs sampling iterations.\n",
        "\n",
        "    Returns:\n",
        "      Z: List (length N) of lists of topic assignments for each word.\n",
        "      A: Document-topic count matrix (N x K).\n",
        "      B: Topic-word count matrix (K x W).\n",
        "    \"\"\"\n",
        "    N = len(DOCS)         # number of documents\n",
        "    W = len(Vocab)        # vocabulary size\n",
        "\n",
        "    # Initialize document-topic count matrix A: each document starts with the prior alpha for every topic.\n",
        "    A = [[alpha for _ in range(K)] for _ in range(N)]\n",
        "\n",
        "    # Initialize topic-word count matrix B: each topic starts with the beta prior for every word.\n",
        "    B = [[beta for _ in range(W)] for _ in range(K)]\n",
        "\n",
        "    # BSUM: for each topic, the total count over the vocabulary.\n",
        "    BSUM = [beta * W for _ in range(K)]\n",
        "\n",
        "    # Z: topic assignments for each word in each document.\n",
        "    # We initialize with -1 to indicate that no topic is assigned initially.\n",
        "    Z = [[-1 for _ in doc] for doc in DOCS]\n",
        "\n",
        "    # Gibbs sampling iterations.\n",
        "    for it in range(iterations):\n",
        "        for d, doc in enumerate(DOCS):\n",
        "            for i, w in enumerate(doc):\n",
        "                current_topic = Z[d][i]\n",
        "                # If a topic was already assigned, subtract its count.\n",
        "                if current_topic != -1:\n",
        "                    A[d][current_topic] -= 1\n",
        "                    B[current_topic][w] -= 1\n",
        "                    BSUM[current_topic] -= 1\n",
        "\n",
        "                # Compute the unnormalized conditional probability for each topic.\n",
        "                topic_probs = []\n",
        "                for k in range(K):\n",
        "                    # The probability is the product of:\n",
        "                    #   (doc-topic count for topic k) and (topic-word probability for word w)\n",
        "                    # Note: B[k][w] / BSUM[k] is the probability of word w under topic k.\n",
        "                    prob = A[d][k] * (B[k][w] / BSUM[k])\n",
        "                    topic_probs.append(prob)\n",
        "\n",
        "                # Sample a new topic from the computed discrete distribution.\n",
        "                new_topic = discrete_sample(topic_probs)\n",
        "\n",
        "                # Update the topic assignment and counts.\n",
        "                Z[d][i] = new_topic\n",
        "                A[d][new_topic] += 1\n",
        "                B[new_topic][w] += 1\n",
        "                BSUM[new_topic] += 1\n",
        "\n",
        "        print(f\"Iteration {it+1} completed.\")\n",
        "\n",
        "    return Z, A, B\n",
        "\n",
        "# ---------------------------\n",
        "# Example usage on a toy dataset:\n",
        "if __name__ == '__main__':\n",
        "    # Example vocabulary (for demonstration purposes)\n",
        "    Vocab = [\"apple\", \"banana\", \"cat\", \"dog\"]\n",
        "    # Example documents represented by lists of word indices (each index points into Vocab)\n",
        "    DOCS = [\n",
        "        [0, 1, 0, 2, 3, 0],   # e.g., \"apple banana apple cat dog apple\"\n",
        "        [1, 3, 3, 2, 2, 1],   # e.g., \"banana dog dog cat cat banana\"\n",
        "        [0, 1, 3, 3, 0, 2]    # e.g., \"apple banana dog dog apple cat\"\n",
        "    ]\n",
        "\n",
        "    # Set number of topics, e.g., 2 (in a larger example you might use K=6 or more)\n",
        "    K = 2\n",
        "    # Hyperparameters for the Dirichlet priors:\n",
        "    alpha = 5.0\n",
        "    beta = 2.0\n",
        "    # Number of Gibbs sampling iterations:\n",
        "    iterations = 100\n",
        "\n",
        "    # Run the baby-LDA Gibbs sampler.\n",
        "    Z, A, B = baby_lda(DOCS, Vocab, K, alpha, beta, iterations)\n",
        "\n",
        "    # Display the resulting topic assignments for each document.\n",
        "    print(\"\\nFinal topic assignments (each sublist corresponds to a document):\")\n",
        "    for d, topics in enumerate(Z):\n",
        "        print(f\"Document {d+1}: {topics}\")\n",
        "\n",
        "    # Display the document-topic counts.\n",
        "    print(\"\\nDocument-topic matrix (A):\")\n",
        "    for d, counts in enumerate(A):\n",
        "        print(f\"Document {d+1}: {counts}\")\n",
        "\n",
        "    # Display the topic-word counts with top words for each topic.\n",
        "    print(\"\\nTopic-word distributions (B):\")\n",
        "    for k, word_counts in enumerate(B):\n",
        "        # Sort words by count (high to low)\n",
        "        sorted_words = sorted([(Vocab[w], word_counts[w]) for w in range(len(Vocab))],\n",
        "                              key=lambda x: x[1],\n",
        "                              reverse=True)\n",
        "        print(f\"Topic {k+1}: {sorted_words}\")\n",
        "\n",
        "    # Note:\n",
        "    # In practice one might also generate wordclouds per topic, for instance using the matplotlib wordcloud package,\n",
        "    # but here we simply print the top words by count."
      ],
      "metadata": {
        "id": "F-ZfouzifUaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}