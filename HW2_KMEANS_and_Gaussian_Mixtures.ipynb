{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqiTHQJ5trtQjbX3P8CDE6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HalgasAdrian/CS5230-Coursework/blob/main/HW2_KMEANS_and_Gaussian_Mixtures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW2 KMNEANS and Gaussian Mixtures\n"
      ],
      "metadata": {
        "id": "HgHKiMWqdlOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: KMeans Theory"
      ],
      "metadata": {
        "id": "lDQcHIupik_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: KMeans on data\n",
        "\n",
        "Using Euclidian distance or dot product similarity (choose one per dataset, you can try other similarity metrics).\n",
        "\n",
        "A) run KMeans on the MNIST Dataset, try K=10\n",
        "\n",
        "B) run KMeans on the FASHION Dataset, try K=10\n",
        "\n",
        "C) run KMeans on the 20NG Dataset, try K=20\n",
        "\n",
        "You can use a library for distance/similarity but you have to implement your own kmeans (EM steps, termination criteria etc).\n",
        "For all three datasets, evaluate the KMeans objective for a higher K (for example double) or smaller K(for example half).\n",
        "For all three datasets, evaluate external clustering performance using data labels and performance metrics Purity and Gini Index (see [A] book section 6.9.2).\n",
        "\n",
        "D) run soft Kmeans for MNIST dataset, use K=10. You can try beta=0.1, beta=1, beta=10. Evaluate performance."
      ],
      "metadata": {
        "id": "IyTCpu1AkHML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) Run KMeans on the MNIST Dataset, try K = 10"
      ],
      "metadata": {
        "id": "3Jzpkszmk6EE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhb50uGrGvTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "eee62198-48b0-4ab4-a883-fd8b1c123723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 02:22:34--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225332/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 02:22:35--  https://web.archive.org/web/20220331225332/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/train-images-idx3-ubyte.gz’\n",
            "\n",
            "/content/mnist/trai 100%[===================>]   9.45M  14.1MB/s    in 0.7s    \n",
            "\n",
            "2025-02-03 02:22:37 (14.1 MB/s) - ‘/content/mnist/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2025-02-03 02:22:37--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225243/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 02:22:38--  https://web.archive.org/web/20220331225243/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/train-labels-idx1-ubyte.gz’\n",
            "\n",
            "/content/mnist/trai 100%[===================>]  28.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 02:22:39 (67.2 MB/s) - ‘/content/mnist/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2025-02-03 02:22:39--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225223/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 02:22:40--  https://web.archive.org/web/20220331225223/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "/content/mnist/t10k 100%[===================>]   1.57M  4.19MB/s    in 0.4s    \n",
            "\n",
            "2025-02-03 02:22:41 (4.19 MB/s) - ‘/content/mnist/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2025-02-03 02:22:41--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225222/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 02:22:42--  https://web.archive.org/web/20220331225222/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "/content/mnist/t10k 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 02:22:43 (1.25 GB/s) - ‘/content/mnist/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "All MNIST files downloaded.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_url = 'https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/'\n",
        "files = [\n",
        "    'train-images-idx3-ubyte.gz',\n",
        "    'train-labels-idx1-ubyte.gz',\n",
        "    't10k-images-idx3-ubyte.gz',\n",
        "    't10k-labels-idx1-ubyte.gz'\n",
        "]\n",
        "\n",
        "# Directory to store MNIST data\n",
        "os.makedirs('/content/mnist', exist_ok=True)\n",
        "\n",
        "# Download each file\n",
        "for file in files:\n",
        "    url = f\"{base_url}{file}\"\n",
        "    output_path = f\"/content/mnist/{file}\"\n",
        "    !wget -O {output_path} {url}\n",
        "\n",
        "print(\"All MNIST files downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract gzip files\n",
        "def extract_gz(file_path, out_path):\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "        with open(out_path, 'wb') as f_out:\n",
        "            f_out.write(f_in.read())\n",
        "\n",
        "# Extract MNIST files\n",
        "mnist_dir = '/content/mnist'\n",
        "for file in files:\n",
        "    gz_path = os.path.join(mnist_dir, file)\n",
        "    out_path = gz_path.replace('.gz', '')\n",
        "    extract_gz(gz_path, out_path)\n",
        "\n",
        "print(\"All MNIST files extracted.\")\n",
        "\n",
        "# Function to parse MNIST image files\n",
        "def load_mnist_images(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        f.read(16)  # Skip header\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        return data.reshape(-1, 28, 28)\n",
        "\n",
        "# Function to parse MNIST label files\n",
        "def load_mnist_labels(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        f.read(8)  # Skip header\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        return data\n",
        "\n",
        "# Load training and test data\n",
        "X_train_mnist = load_mnist_images('/content/mnist/train-images-idx3-ubyte')\n",
        "y_train_mnist = load_mnist_labels('/content/mnist/train-labels-idx1-ubyte')\n",
        "X_test_mnist = load_mnist_images('/content/mnist/t10k-images-idx3-ubyte')\n",
        "y_test_mnist = load_mnist_labels('/content/mnist/t10k-labels-idx1-ubyte')\n",
        "\n",
        "print(\"MNIST data successfully loaded.\")"
      ],
      "metadata": {
        "id": "uPyDffZenRLm",
        "outputId": "96b596c8-c4e8-4cf5-b9d5-be29b3ffbf1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All MNIST files extracted.\n",
            "MNIST data successfully loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans from scratch"
      ],
      "metadata": {
        "id": "NrRS0tXVptsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KMeans:\n",
        "    def __init__(self, n_clusters=10, max_iter=300, tol=1e-4):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.centroids = None\n",
        "        self.labels = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize centroids randomly\n",
        "        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
        "        self.centroids = X[random_indices]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            # Assign clusters\n",
        "            distances = self._compute_distances(X)\n",
        "            self.labels = np.argmin(distances, axis=1)\n",
        "\n",
        "            # Update centroids\n",
        "            new_centroids = np.array([X[self.labels == k].mean(axis=0) for k in range(self.n_clusters)])\n",
        "\n",
        "            # Check for convergence\n",
        "            if np.linalg.norm(new_centroids - self.centroids) < self.tol:\n",
        "                break\n",
        "\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "    def _compute_distances(self, X):\n",
        "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
        "        for k in range(self.n_clusters):\n",
        "            distances[:, k] = np.linalg.norm(X - self.centroids[k], axis=1)\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "        distances = self._compute_distances(X)\n",
        "        return np.argmin(distances, axis=1)"
      ],
      "metadata": {
        "id": "D6AxSaDtnm92"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kmeans on MNIST Dataset with K = 10"
      ],
      "metadata": {
        "id": "pA80K9D5pzM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the MNIST images\n",
        "X_train_mnist_flat = X_train_mnist.reshape(X_train_mnist.shape[0], -1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train_mnist_flat = X_train_mnist_flat / 255.0\n",
        "\n",
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=10)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=10): {objective_mnist}\")"
      ],
      "metadata": {
        "id": "0JevwN6Rp2N4",
        "outputId": "930e2a47-6dc2-47bc-ef8b-7a689554658a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for MNIST (K=10): 2352952.706814831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(confusion_mat, axis=0)\n",
        "    cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n",
        "    return 1 - np.sum(cluster_purities**2)\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_mnist}\")"
      ],
      "metadata": {
        "id": "wj-c9Bn_rrjT",
        "outputId": "7a303dd0-acad-427f-9d78-78110d45d64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=10): 0.5828\n",
            "Gini Index for MNIST (K=10): -3.375299139898414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST KMEANS K=20 with external clustering performance."
      ],
      "metadata": {
        "id": "6bVbrKUjvMzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=20)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=20): {objective_mnist}\")\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_mnist}\")"
      ],
      "metadata": {
        "id": "tyc3DDoZvMWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST KMEANS K=5 with external clustering performance."
      ],
      "metadata": {
        "id": "Bm_0BM_vvSpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=5)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=5): {objective_mnist}\")\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=5): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=5): {gini_mnist}\")"
      ],
      "metadata": {
        "id": "A-uD1-nwvW_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) run KMeans on the FASHION Dataset, try K=10"
      ],
      "metadata": {
        "id": "Wncq5SX5Tyt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we must load and prepare the data."
      ],
      "metadata": {
        "id": "lxNffMhuYcsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory\n",
        "!mkdir -p /content/fashion-mnist\n",
        "\n",
        "# Download files directly to the target directory\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "# Extract files using Python's gzip (no overwrite prompts)\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "for gz_file in ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz',\n",
        "                't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']:\n",
        "    with gzip.open(f'/content/fashion-mnist/{gz_file}', 'rb') as f_in:\n",
        "        with open(f'/content/fashion-mnist/{gz_file[:-3]}', 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"Files successfully downloaded and extracted!\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9q3ub1dUCNY",
        "outputId": "735f271b-0b6b-4bbc-ff34-1efdaffd238e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 19:54:45--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 19:54:45--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26421880 (25M) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]  25.20M  46.9MB/s    in 0.5s    \n",
            "\n",
            "2025-02-03 19:54:48 (46.9 MB/s) - ‘/content/fashion-mnist/train-images-idx3-ubyte.gz’ saved [26421880/26421880]\n",
            "\n",
            "--2025-02-03 19:54:48--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 19:54:49--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29515 (29K) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.82K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-03 19:54:49 (2.91 MB/s) - ‘/content/fashion-mnist/train-labels-idx1-ubyte.gz’ saved [29515/29515]\n",
            "\n",
            "--2025-02-03 19:54:49--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 19:54:50--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4422102 (4.2M) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   4.22M  13.8MB/s    in 0.3s    \n",
            "\n",
            "2025-02-03 19:54:51 (13.8 MB/s) - ‘/content/fashion-mnist/t10k-images-idx3-ubyte.gz’ saved [4422102/4422102]\n",
            "\n",
            "--2025-02-03 19:54:51--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 19:54:51--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5148 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   5.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 19:54:52 (59.5 MB/s) - ‘/content/fashion-mnist/t10k-labels-idx1-ubyte.gz’ saved [5148/5148]\n",
            "\n",
            "Files successfully downloaded and extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_fashion(path, kind='train'):\n",
        "    \"\"\"Load Fashion MNIST data from path\"\"\"\n",
        "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte')\n",
        "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte')\n",
        "\n",
        "    with open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                             offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images.reshape(-1, 28, 28), labels\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    X_train_fashion, y_train_fashion = load_fashion('/content/fashion-mnist', kind='train')\n",
        "    X_test_fashion, y_test_fashion = load_fashion('/content/fashion-mnist', kind='t10k')\n",
        "    print(\"Data loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWioOjkyXTTi",
        "outputId": "1ede828a-692c-4bb5-bdfd-050ee25b3aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with our data loaded we can run KMEANS on the FASHION dataset."
      ],
      "metadata": {
        "id": "TIG_2IcBYghH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the Fashion images\n",
        "X_train_fashion_flat = X_train_fashion.reshape(X_train_fashion.shape[0], -1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train_fashion_flat = X_train_fashion_flat / 255.0\n",
        "\n",
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=10)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=10): {objective_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGaeRobBZRQL",
        "outputId": "23fff95a-3ff3-4154-86f1-f4856f3184f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for FASHION (K=10): 1926913.681605965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(confusion_mat, axis=0)\n",
        "    cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n",
        "    return 1 - np.sum(cluster_purities**2)\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSEmsxJDe-U-",
        "outputId": "04279fe2-a85d-4078-8f43-d8d8dfb695b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=10): 0.5791666666666667\n",
            "Gini Index for MNIST (K=10): -3.6893239708811976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASHION KMEANS K=20 with external clustering performance."
      ],
      "metadata": {
        "id": "kv3XZUscuuP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=20)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=20): {objective_fashion}\")\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_fashion}\")"
      ],
      "metadata": {
        "id": "vlvQ1N0KusGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASHION KMEANS K=5 with external clustering performance."
      ],
      "metadata": {
        "id": "gepTd8jbvAVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=5)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=5): {objective_fashion}\")\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=5): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=5): {gini_fashion}\")"
      ],
      "metadata": {
        "id": "Ui4v0jrqvC3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) run KMeans on the 20NG Dataset, try K=20"
      ],
      "metadata": {
        "id": "gs0joqasfexM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare the data."
      ],
      "metadata": {
        "id": "v70-pJogfmeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the 20 Newsgroups dataset\n",
        "!wget -O /content/20news-bydate.tar.gz 'http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz'\n",
        "\n",
        "# Extract the dataset\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "data_dir = '/content/20news-bydate'\n",
        "with tarfile.open('/content/20news-bydate.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall(path=data_dir)\n",
        "\n",
        "print(f\"Dataset extracted to {data_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TieRiS7vfkQz",
        "outputId": "3fb8df88-d14a-4995-c49e-a51f29eeb426"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 20:28:49--  http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\n",
            "Resolving qwone.com (qwone.com)... 173.48.205.131\n",
            "Connecting to qwone.com (qwone.com)|173.48.205.131|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14464277 (14M) [application/x-gzip]\n",
            "Saving to: ‘/content/20news-bydate.tar.gz’\n",
            "\n",
            "/content/20news-byd 100%[===================>]  13.79M  2.97MB/s    in 5.6s    \n",
            "\n",
            "2025-02-03 20:28:55 (2.47 MB/s) - ‘/content/20news-bydate.tar.gz’ saved [14464277/14464277]\n",
            "\n",
            "Dataset extracted to /content/20news-bydate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on TF-IDF Vectorization:\n",
        "Term Frequency-Inverse Document Frequency is a text representation technique that evaluates how importat a word is to a document relative to a corpus.\n",
        "\n",
        "Term Frequency (TF) = (word count in doc) / (total words in doc) - measures local importance of a word\n",
        "\n",
        "Inverse document frequency (IDF) = log(total docs / docs containing word) - penalizes words common across many docs\n",
        "\n",
        "TF-IDF = TF * IDF - final importance score for each word\n",
        "\n",
        "TfidVectorizer automatically applies L2 Normalization to our output vectors.\n"
      ],
      "metadata": {
        "id": "1BA7Di27p3vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the dataset\n",
        "import os\n",
        "import tarfile\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "data_dir = '/content/20news-bydate'\n",
        "\n",
        "# Check if the directory exists, if not, download and extract\n",
        "train_dir = os.path.join(data_dir, '20news-bydate-train')\n",
        "if not os.path.exists(train_dir):\n",
        "    print(\"Downloading 20 Newsgroups dataset...\")\n",
        "    !wget -O /content/20news-bydate.tar.gz 'http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz'\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with tarfile.open('/content/20news-bydate.tar.gz', 'r:gz') as tar:\n",
        "        tar.extractall(path=data_dir)\n",
        "\n",
        "    print(f\"Dataset extracted to {data_dir}\")\n",
        "def parse_20newsgroups(data_dir):\n",
        "    texts, labels = [], []\n",
        "    label_names = sorted(os.listdir(data_dir))\n",
        "\n",
        "    for label_idx, label_name in enumerate(label_names):\n",
        "        label_path = os.path.join(data_dir, label_name)\n",
        "        if os.path.isdir(label_path):\n",
        "            for file_name in os.listdir(label_path):\n",
        "                file_path = os.path.join(label_path, file_name)\n",
        "                with open(file_path, 'r', errors='ignore') as f:\n",
        "                    texts.append(f.read())\n",
        "                    labels.append(label_idx)\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "    return X, labels, vectorizer.get_feature_names_out()\n",
        "\n",
        "# Process the dataset\n",
        "X_20NG, y_20NG, feature_names_20NG = parse_20newsgroups(os.path.join(data_dir, '20news-bydate-train'))\n",
        "print(f\"20NG Dataset: {len(X_20NG)} samples, {len(feature_names_20NG)} features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqvUQ2oJgMCm",
        "outputId": "4cedc67d-41f6-4983-8f9c-24aeec9809ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20NG Dataset: 11314 samples, 5000 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with 20 NewsGroups loaded we can run our KMEANS with K = 20."
      ],
      "metadata": {
        "id": "J1qocX3ogTSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=20)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=20): {objective_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPX3A__ygXXj",
        "outputId": "07a553f6-fce9-481c-c4ef-5b98981562db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for 20NG (K=20): 10611.215804630583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(confusion_mat, axis=0)\n",
        "    cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n",
        "    return 1 - np.sum(cluster_purities**2)\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYp0Lq12qwr5",
        "outputId": "71397fc4-0e0f-41db-d1e1-e5e0795f5c41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=10): 0.3138589358317129\n",
            "Gini Index for MNIST (K=10): -4.5972506330851735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20NG KMEANS with K = 40 with external clustering performance."
      ],
      "metadata": {
        "id": "r4zyD-kQt9pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=40)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=40): {objective_20NG}\")\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=40): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=40): {gini_20NG}\")"
      ],
      "metadata": {
        "id": "1hvdJEqvt8VC",
        "outputId": "83246a0e-36a1-4515-b1af-bda8c799a48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'KMeans' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-80477562f23a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run KMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans_20NG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkmeans_20NG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_20NG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluate the KMeans objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KMeans' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20NG KMEANS with K = 10 with external clustering performance."
      ],
      "metadata": {
        "id": "CSONNO3JufJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=10)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=10): {objective_20NG}\")\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_20NG}\")"
      ],
      "metadata": {
        "id": "Wyyg3XjxudcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D) run soft Kmeans for MNIST dataset, use K=10. You can try beta=0.1, beta=1, beta=10. Evaluate performance."
      ],
      "metadata": {
        "id": "RA65zIsBtwYm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5e4H4zYXt4Wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}