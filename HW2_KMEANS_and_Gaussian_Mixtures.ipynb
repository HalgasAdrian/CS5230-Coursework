{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMUoawlY2387AM8HguWXY8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HalgasAdrian/CS5230-Coursework/blob/main/HW2_KMEANS_and_Gaussian_Mixtures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HW2 KMNEANS and Gaussian Mixtures\n"
      ],
      "metadata": {
        "id": "HgHKiMWqdlOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: KMeans Theory"
      ],
      "metadata": {
        "id": "lDQcHIupik_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: KMeans on data\n",
        "\n",
        "Using Euclidian distance or dot product similarity (choose one per dataset, you can try other similarity metrics).\n",
        "\n",
        "A) run KMeans on the MNIST Dataset, try K=10\n",
        "\n",
        "B) run KMeans on the FASHION Dataset, try K=10\n",
        "\n",
        "C) run KMeans on the 20NG Dataset, try K=20\n",
        "\n",
        "You can use a library for distance/similarity but you have to implement your own kmeans (EM steps, termination criteria etc).\n",
        "For all three datasets, evaluate the KMeans objective for a higher K (for example double) or smaller K(for example half).\n",
        "For all three datasets, evaluate external clustering performance using data labels and performance metrics Purity and Gini Index (see [A] book section 6.9.2).\n",
        "\n",
        "D) run soft Kmeans for MNIST dataset, use K=10. You can try beta=0.1, beta=1, beta=10. Evaluate performance."
      ],
      "metadata": {
        "id": "IyTCpu1AkHML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) Run KMeans on the MNIST Dataset, try K = 10"
      ],
      "metadata": {
        "id": "3Jzpkszmk6EE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yhb50uGrGvTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fe504766-5caf-45c9-a5a0-2764b56c8f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 21:38:49--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225332/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 21:38:51--  https://web.archive.org/web/20220331225332/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/train-images-idx3-ubyte.gz’\n",
            "\n",
            "/content/mnist/trai 100%[===================>]   9.45M  45.3MB/s    in 0.2s    \n",
            "\n",
            "2025-02-03 21:38:54 (45.3 MB/s) - ‘/content/mnist/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2025-02-03 21:38:54--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225243/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 21:38:55--  https://web.archive.org/web/20220331225243/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/train-labels-idx1-ubyte.gz’\n",
            "\n",
            "/content/mnist/trai 100%[===================>]  28.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 21:38:58 (307 MB/s) - ‘/content/mnist/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2025-02-03 21:38:58--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225223/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 21:38:59--  https://web.archive.org/web/20220331225223/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "/content/mnist/t10k 100%[===================>]   1.57M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-02-03 21:39:00 (17.6 MB/s) - ‘/content/mnist/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2025-02-03 21:39:01--  https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving web.archive.org (web.archive.org)... 207.241.237.3\n",
            "Connecting to web.archive.org (web.archive.org)|207.241.237.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://web.archive.org/web/20220331225222/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 21:39:01--  https://web.archive.org/web/20220331225222/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Reusing existing connection to web.archive.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist/t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "/content/mnist/t10k 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 21:39:02 (4.16 GB/s) - ‘/content/mnist/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "All MNIST files downloaded.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_url = 'https://web.archive.org/web/20220331230320/http://yann.lecun.com/exdb/mnist/'\n",
        "files = [\n",
        "    'train-images-idx3-ubyte.gz',\n",
        "    'train-labels-idx1-ubyte.gz',\n",
        "    't10k-images-idx3-ubyte.gz',\n",
        "    't10k-labels-idx1-ubyte.gz'\n",
        "]\n",
        "\n",
        "# Directory to store MNIST data\n",
        "os.makedirs('/content/mnist', exist_ok=True)\n",
        "\n",
        "# Download each file\n",
        "for file in files:\n",
        "    url = f\"{base_url}{file}\"\n",
        "    output_path = f\"/content/mnist/{file}\"\n",
        "    !wget -O {output_path} {url}\n",
        "\n",
        "print(\"All MNIST files downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract gzip files\n",
        "def extract_gz(file_path, out_path):\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "        with open(out_path, 'wb') as f_out:\n",
        "            f_out.write(f_in.read())\n",
        "\n",
        "# Extract MNIST files\n",
        "mnist_dir = '/content/mnist'\n",
        "for file in files:\n",
        "    gz_path = os.path.join(mnist_dir, file)\n",
        "    out_path = gz_path.replace('.gz', '')\n",
        "    extract_gz(gz_path, out_path)\n",
        "\n",
        "print(\"All MNIST files extracted.\")\n",
        "\n",
        "# Function to parse MNIST image files\n",
        "def load_mnist_images(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        f.read(16)  # Skip header\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        return data.reshape(-1, 28, 28)\n",
        "\n",
        "# Function to parse MNIST label files\n",
        "def load_mnist_labels(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        f.read(8)  # Skip header\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        return data\n",
        "\n",
        "# Load training and test data\n",
        "X_train_mnist = load_mnist_images('/content/mnist/train-images-idx3-ubyte')\n",
        "y_train_mnist = load_mnist_labels('/content/mnist/train-labels-idx1-ubyte')\n",
        "X_test_mnist = load_mnist_images('/content/mnist/t10k-images-idx3-ubyte')\n",
        "y_test_mnist = load_mnist_labels('/content/mnist/t10k-labels-idx1-ubyte')\n",
        "\n",
        "print(\"MNIST data successfully loaded.\")"
      ],
      "metadata": {
        "id": "uPyDffZenRLm",
        "outputId": "c389eef6-efc9-4fc7-aeb5-8cce40311b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All MNIST files extracted.\n",
            "MNIST data successfully loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans from scratch"
      ],
      "metadata": {
        "id": "NrRS0tXVptsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KMeans:\n",
        "    def __init__(self, n_clusters=10, max_iter=300, tol=1e-4):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.centroids = None\n",
        "        self.labels = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize centroids randomly\n",
        "        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
        "        self.centroids = X[random_indices]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            # Assign clusters\n",
        "            distances = self._compute_distances(X)\n",
        "            self.labels = np.argmin(distances, axis=1)\n",
        "\n",
        "            # Update centroids\n",
        "            new_centroids = np.array([X[self.labels == k].mean(axis=0) for k in range(self.n_clusters)])\n",
        "\n",
        "            # Check for convergence\n",
        "            if np.linalg.norm(new_centroids - self.centroids) < self.tol:\n",
        "                break\n",
        "\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "    def _compute_distances(self, X):\n",
        "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
        "        for k in range(self.n_clusters):\n",
        "            distances[:, k] = np.linalg.norm(X - self.centroids[k], axis=1)\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "        distances = self._compute_distances(X)\n",
        "        return np.argmin(distances, axis=1)"
      ],
      "metadata": {
        "id": "D6AxSaDtnm92"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kmeans on MNIST Dataset with K = 10"
      ],
      "metadata": {
        "id": "pA80K9D5pzM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the MNIST images\n",
        "X_train_mnist_flat = X_train_mnist.reshape(X_train_mnist.shape[0], -1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train_mnist_flat = X_train_mnist_flat / 255.0\n",
        "\n",
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=10)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=10): {objective_mnist}\")"
      ],
      "metadata": {
        "id": "0JevwN6Rp2N4",
        "outputId": "630a1517-8fbf-4b78-aa96-17b954107f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for MNIST (K=10): 2352828.0140824346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    contingency = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(contingency, axis=0)\n",
        "\n",
        "    # Handle empty clusters and division by zero\n",
        "    valid_clusters = cluster_sizes > 0\n",
        "    if np.sum(valid_clusters) == 0:\n",
        "        return 1.0  # Return worst case when all clusters are empty\n",
        "\n",
        "    # Calculate purities only for valid clusters\n",
        "    cluster_purities = np.zeros_like(cluster_sizes, dtype=np.float64)\n",
        "    cluster_purities[valid_clusters] = np.amax(contingency[:, valid_clusters], axis=0) / cluster_sizes[valid_clusters]\n",
        "\n",
        "    # Calculate weighted Gini index (proper formula)\n",
        "    total_samples = np.sum(cluster_sizes)\n",
        "    weights = cluster_sizes[valid_clusters] / total_samples\n",
        "    gini = 1 - np.sum(weights * (cluster_purities[valid_clusters] ** 2))\n",
        "\n",
        "    return np.clip(gini, 0.0, 1.0)  # Ensure valid range\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_mnist}\")"
      ],
      "metadata": {
        "id": "wj-c9Bn_rrjT",
        "outputId": "078da486-3fdb-4bf3-c9f3-7058f454d25b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=10): 0.5906166666666667\n",
            "Gini Index for MNIST (K=10): -3.5202164052678473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST KMEANS K=20 with external clustering performance."
      ],
      "metadata": {
        "id": "6bVbrKUjvMzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=20)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=20): {objective_mnist}\")\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_mnist}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyc3DDoZvMWU",
        "outputId": "4ece9788-2fe0-40de-87ba-fe674bf7db78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for MNIST (K=20): 2111559.14306655\n",
            "Purity for MNIST (K=20): 0.7052666666666667\n",
            "Gini Index for MNIST (K=20): -10.586305611930403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST KMEANS K=5 with external clustering performance."
      ],
      "metadata": {
        "id": "Bm_0BM_vvSpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_mnist = KMeans(n_clusters=5)\n",
        "kmeans_mnist.fit(X_train_mnist_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_mnist = kmeans_objective(X_train_mnist_flat, kmeans_mnist.centroids, kmeans_mnist.labels)\n",
        "print(f\"KMeans Objective for MNIST (K=5): {objective_mnist}\")\n",
        "\n",
        "purity_mnist = purity_score(y_train_mnist, kmeans_mnist.labels)\n",
        "gini_mnist = gini_index(y_train_mnist, kmeans_mnist.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=5): {purity_mnist}\")\n",
        "print(f\"Gini Index for MNIST (K=5): {gini_mnist}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-uD1-nwvW_M",
        "outputId": "06941716-ad56-4ca0-b9f6-ae651b224206"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for MNIST (K=5): 2605960.404855432\n",
            "Purity for MNIST (K=5): 0.45236666666666664\n",
            "Gini Index for MNIST (K=5): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e29d13acec4f>:10: RuntimeWarning: invalid value encountered in divide\n",
            "  cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) run KMeans on the FASHION Dataset, try K=10"
      ],
      "metadata": {
        "id": "Wncq5SX5Tyt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we must load and prepare the data."
      ],
      "metadata": {
        "id": "lxNffMhuYcsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory\n",
        "!mkdir -p /content/fashion-mnist\n",
        "\n",
        "# Download files directly to the target directory\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
        "!wget -P /content/fashion-mnist https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "# Extract files using Python's gzip (no overwrite prompts)\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "for gz_file in ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz',\n",
        "                't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']:\n",
        "    with gzip.open(f'/content/fashion-mnist/{gz_file}', 'rb') as f_in:\n",
        "        with open(f'/content/fashion-mnist/{gz_file[:-3]}', 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"Files successfully downloaded and extracted!\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9q3ub1dUCNY",
        "outputId": "bc998138-7164-48cb-fb82-91b4c165bf48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 21:49:29--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 21:49:29--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26421880 (25M) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]  25.20M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-03 21:49:30 (263 MB/s) - ‘/content/fashion-mnist/train-images-idx3-ubyte.gz’ saved [26421880/26421880]\n",
            "\n",
            "--2025-02-03 21:49:30--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 21:49:31--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29515 (29K) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.82K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-02-03 21:49:31 (18.6 MB/s) - ‘/content/fashion-mnist/train-labels-idx1-ubyte.gz’ saved [29515/29515]\n",
            "\n",
            "--2025-02-03 21:49:31--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz [following]\n",
            "--2025-02-03 21:49:32--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4422102 (4.2M) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   4.22M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-03 21:49:32 (62.6 MB/s) - ‘/content/fashion-mnist/t10k-images-idx3-ubyte.gz’ saved [4422102/4422102]\n",
            "\n",
            "--2025-02-03 21:49:32--  https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz [following]\n",
            "--2025-02-03 21:49:33--  https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5148 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘/content/fashion-mnist/t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   5.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 21:49:33 (70.5 MB/s) - ‘/content/fashion-mnist/t10k-labels-idx1-ubyte.gz’ saved [5148/5148]\n",
            "\n",
            "Files successfully downloaded and extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_fashion(path, kind='train'):\n",
        "    \"\"\"Load Fashion MNIST data from path\"\"\"\n",
        "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte')\n",
        "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte')\n",
        "\n",
        "    with open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                             offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images.reshape(-1, 28, 28), labels\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    X_train_fashion, y_train_fashion = load_fashion('/content/fashion-mnist', kind='train')\n",
        "    X_test_fashion, y_test_fashion = load_fashion('/content/fashion-mnist', kind='t10k')\n",
        "    print(\"Data loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWioOjkyXTTi",
        "outputId": "c30463c4-3a37-40b0-d4e3-983d60ee226a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with our data loaded we can run KMEANS on the FASHION dataset."
      ],
      "metadata": {
        "id": "TIG_2IcBYghH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the Fashion images\n",
        "X_train_fashion_flat = X_train_fashion.reshape(X_train_fashion.shape[0], -1)\n",
        "\n",
        "# Normalize the data\n",
        "X_train_fashion_flat = X_train_fashion_flat / 255.0\n",
        "\n",
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=10)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=10): {objective_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGaeRobBZRQL",
        "outputId": "9112bedc-f568-49ec-9ec2-54b86361405a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for FASHION (K=10): 1906653.2385860477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    contingency = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(contingency, axis=0)\n",
        "\n",
        "    # Handle empty clusters and division by zero\n",
        "    valid_clusters = cluster_sizes > 0\n",
        "    if np.sum(valid_clusters) == 0:\n",
        "        return 1.0  # Return worst case when all clusters are empty\n",
        "\n",
        "    # Calculate purities only for valid clusters\n",
        "    cluster_purities = np.zeros_like(cluster_sizes, dtype=np.float64)\n",
        "    cluster_purities[valid_clusters] = np.amax(contingency[:, valid_clusters], axis=0) / cluster_sizes[valid_clusters]\n",
        "\n",
        "    # Calculate weighted Gini index (proper formula)\n",
        "    total_samples = np.sum(cluster_sizes)\n",
        "    weights = cluster_sizes[valid_clusters] / total_samples\n",
        "    gini = 1 - np.sum(weights * (cluster_purities[valid_clusters] ** 2))\n",
        "\n",
        "    return np.clip(gini, 0.0, 1.0)  # Ensure valid range\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSEmsxJDe-U-",
        "outputId": "b0a3d4ed-f271-4da2-d3fa-566d7762d879"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=10): 0.5535666666666667\n",
            "Gini Index for MNIST (K=10): -3.6140723217252573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASHION KMEANS K=20 with external clustering performance."
      ],
      "metadata": {
        "id": "kv3XZUscuuP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=20)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=20): {objective_fashion}\")\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlvQ1N0KusGG",
        "outputId": "378b94b7-a157-4b13-b5aa-7f9aa549bada"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for FASHION (K=20): 1609106.6014856338\n",
            "Purity for MNIST (K=20): 0.6614333333333333\n",
            "Gini Index for MNIST (K=20): -9.366613925981754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASHION KMEANS K=5 with external clustering performance."
      ],
      "metadata": {
        "id": "gepTd8jbvAVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_fashion = KMeans(n_clusters=5)\n",
        "kmeans_fashion.fit(X_train_fashion_flat)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_fashion = kmeans_objective(X_train_fashion_flat, kmeans_fashion.centroids, kmeans_fashion.labels)\n",
        "print(f\"KMeans Objective for FASHION (K=5): {objective_fashion}\")\n",
        "\n",
        "purity_fashion = purity_score(y_train_fashion, kmeans_fashion.labels)\n",
        "gini_fashion = gini_index(y_train_fashion, kmeans_fashion.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=5): {purity_fashion}\")\n",
        "print(f\"Gini Index for MNIST (K=5): {gini_fashion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui4v0jrqvC3G",
        "outputId": "b68094ae-f498-4c9e-f65b-22715b6ff298"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for FASHION (K=5): 2352605.6906437874\n",
            "Purity for MNIST (K=5): 0.41091666666666665\n",
            "Gini Index for MNIST (K=5): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cf48c710b723>:10: RuntimeWarning: invalid value encountered in divide\n",
            "  cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) run KMeans on the 20NG Dataset, try K=20"
      ],
      "metadata": {
        "id": "gs0joqasfexM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare the data."
      ],
      "metadata": {
        "id": "v70-pJogfmeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the 20 Newsgroups dataset\n",
        "!wget -O /content/20news-bydate.tar.gz 'http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz'\n",
        "\n",
        "# Extract the dataset\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "data_dir = '/content/20news-bydate'\n",
        "with tarfile.open('/content/20news-bydate.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall(path=data_dir)\n",
        "\n",
        "print(f\"Dataset extracted to {data_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TieRiS7vfkQz",
        "outputId": "5eb6d92d-1e89-4863-a05a-efdccca664bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 22:01:24--  http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\n",
            "Resolving qwone.com (qwone.com)... 173.48.205.131\n",
            "Connecting to qwone.com (qwone.com)|173.48.205.131|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14464277 (14M) [application/x-gzip]\n",
            "Saving to: ‘/content/20news-bydate.tar.gz’\n",
            "\n",
            "/content/20news-byd 100%[===================>]  13.79M  5.32MB/s    in 2.6s    \n",
            "\n",
            "2025-02-03 22:01:26 (5.32 MB/s) - ‘/content/20news-bydate.tar.gz’ saved [14464277/14464277]\n",
            "\n",
            "Dataset extracted to /content/20news-bydate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on TF-IDF Vectorization:\n",
        "Term Frequency-Inverse Document Frequency is a text representation technique that evaluates how importat a word is to a document relative to a corpus.\n",
        "\n",
        "Term Frequency (TF) = (word count in doc) / (total words in doc) - measures local importance of a word\n",
        "\n",
        "Inverse document frequency (IDF) = log(total docs / docs containing word) - penalizes words common across many docs\n",
        "\n",
        "TF-IDF = TF * IDF - final importance score for each word\n",
        "\n",
        "TfidVectorizer automatically applies L2 Normalization to our output vectors.\n"
      ],
      "metadata": {
        "id": "1BA7Di27p3vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the dataset\n",
        "import os\n",
        "import tarfile\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "data_dir = '/content/20news-bydate'\n",
        "\n",
        "# Check if the directory exists, if not, download and extract\n",
        "train_dir = os.path.join(data_dir, '20news-bydate-train')\n",
        "if not os.path.exists(train_dir):\n",
        "    print(\"Downloading 20 Newsgroups dataset...\")\n",
        "    !wget -O /content/20news-bydate.tar.gz 'http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz'\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with tarfile.open('/content/20news-bydate.tar.gz', 'r:gz') as tar:\n",
        "        tar.extractall(path=data_dir)\n",
        "\n",
        "    print(f\"Dataset extracted to {data_dir}\")\n",
        "def parse_20newsgroups(data_dir):\n",
        "    texts, labels = [], []\n",
        "    label_names = sorted(os.listdir(data_dir))\n",
        "\n",
        "    for label_idx, label_name in enumerate(label_names):\n",
        "        label_path = os.path.join(data_dir, label_name)\n",
        "        if os.path.isdir(label_path):\n",
        "            for file_name in os.listdir(label_path):\n",
        "                file_path = os.path.join(label_path, file_name)\n",
        "                with open(file_path, 'r', errors='ignore') as f:\n",
        "                    texts.append(f.read())\n",
        "                    labels.append(label_idx)\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    X = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "    return X, labels, vectorizer.get_feature_names_out()\n",
        "\n",
        "# Process the dataset\n",
        "X_20NG, y_20NG, feature_names_20NG = parse_20newsgroups(os.path.join(data_dir, '20news-bydate-train'))\n",
        "print(f\"20NG Dataset: {len(X_20NG)} samples, {len(feature_names_20NG)} features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqvUQ2oJgMCm",
        "outputId": "47ad4dcd-a0cc-4ed7-87d4-f37e584680fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20NG Dataset: 11314 samples, 5000 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with 20 NewsGroups loaded we can run our KMEANS with K = 20."
      ],
      "metadata": {
        "id": "J1qocX3ogTSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=20)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=20): {objective_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPX3A__ygXXj",
        "outputId": "4eb1ddd3-7257-4a4f-83cd-36031342ef8f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for 20NG (K=20): 10588.172849674344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(confusion_mat, axis=0)) / np.sum(confusion_mat)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    contingency = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(contingency, axis=0)\n",
        "\n",
        "    # Handle empty clusters and division by zero\n",
        "    valid_clusters = cluster_sizes > 0\n",
        "    if np.sum(valid_clusters) == 0:\n",
        "        return 1.0  # Return worst case when all clusters are empty\n",
        "\n",
        "    # Calculate purities only for valid clusters\n",
        "    cluster_purities = np.zeros_like(cluster_sizes, dtype=np.float64)\n",
        "    cluster_purities[valid_clusters] = np.amax(contingency[:, valid_clusters], axis=0) / cluster_sizes[valid_clusters]\n",
        "\n",
        "    # Calculate weighted Gini index (proper formula)\n",
        "    total_samples = np.sum(cluster_sizes)\n",
        "    weights = cluster_sizes[valid_clusters] / total_samples\n",
        "    gini = 1 - np.sum(weights * (cluster_purities[valid_clusters] ** 2))\n",
        "\n",
        "    return np.clip(gini, 0.0, 1.0)  # Ensure valid range\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=20): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=20): {gini_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYp0Lq12qwr5",
        "outputId": "a0278887-54b4-43b0-c648-0690b9fa3818"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity for MNIST (K=20): 0.3485062754109952\n",
            "Gini Index for MNIST (K=20): -6.627868808990032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20NG KMEANS with K = 40 with external clustering performance."
      ],
      "metadata": {
        "id": "r4zyD-kQt9pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=40)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=40): {objective_20NG}\")\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=40): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=40): {gini_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hvdJEqvt8VC",
        "outputId": "5bc42fe0-bae4-4520-ef78-60b5d39f89e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for 20NG (K=40): 10324.724013294199\n",
            "Purity for MNIST (K=40): 0.40215662011666964\n",
            "Gini Index for MNIST (K=40): -12.106054976888613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20NG KMEANS with K = 10 with external clustering performance."
      ],
      "metadata": {
        "id": "CSONNO3JufJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans\n",
        "kmeans_20NG = KMeans(n_clusters=10)\n",
        "kmeans_20NG.fit(X_20NG)\n",
        "\n",
        "# Evaluate the KMeans objective\n",
        "def kmeans_objective(X, centroids, labels):\n",
        "    return np.sum([np.linalg.norm(X[labels == k] - centroids[k])**2 for k in range(centroids.shape[0])])\n",
        "\n",
        "objective_20NG = kmeans_objective(X_20NG, kmeans_20NG.centroids, kmeans_20NG.labels)\n",
        "print(f\"KMeans Objective for 20NG (K=10): {objective_20NG}\")\n",
        "\n",
        "purity_20NG = purity_score(y_20NG, kmeans_20NG.labels)\n",
        "gini_20NG = gini_index(y_20NG, kmeans_20NG.labels)\n",
        "\n",
        "print(f\"Purity for MNIST (K=10): {purity_20NG}\")\n",
        "print(f\"Gini Index for MNIST (K=10): {gini_20NG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyyg3XjxudcF",
        "outputId": "b53267a3-2568-43c8-9c69-794614c57dfd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans Objective for 20NG (K=10): 10766.72516519991\n",
            "Purity for MNIST (K=10): 0.32587944140003533\n",
            "Gini Index for MNIST (K=10): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-229c53d8b175>:10: RuntimeWarning: invalid value encountered in divide\n",
            "  cluster_purities = np.amax(confusion_mat, axis=0) / cluster_sizes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D) run soft Kmeans for MNIST dataset, use K=10. You can try beta=0.1, beta=1, beta=10. Evaluate performance."
      ],
      "metadata": {
        "id": "RA65zIsBtwYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class SoftKMeans:\n",
        "    def __init__(self, n_clusters=10, max_iter=100, tol=1e-4, beta=1.0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.beta = beta\n",
        "        self.centroids = None\n",
        "        self.responsibilities = None\n",
        "\n",
        "    def _compute_distances(self, X):\n",
        "        \"\"\"Calculate Euclidean distances between data points and centroids\"\"\"\n",
        "        return np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
        "\n",
        "    def _compute_responsibilities(self, distances):\n",
        "        \"\"\"Convert distances to probabilities using softmax with temperature parameter beta\"\"\"\n",
        "        scaled_dist = -self.beta * distances\n",
        "        shifted_scaled = scaled_dist - np.max(scaled_dist, axis=1, keepdims=True)  # For numerical stability\n",
        "        exp_values = np.exp(shifted_scaled)\n",
        "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "    def fit(self, X):\n",
        "        # Initialize centroids randomly\n",
        "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
        "\n",
        "        for _ in range(self.max_iter):\n",
        "            # E-step: Compute responsibilities\n",
        "            distances = self._compute_distances(X)\n",
        "            responsibilities = self._compute_responsibilities(distances)\n",
        "\n",
        "            # M-step: Update centroids\n",
        "            new_centroids = np.zeros_like(self.centroids)\n",
        "            for k in range(self.n_clusters):\n",
        "                weight_sum = np.sum(responsibilities[:, k])\n",
        "                if weight_sum < 1e-8:  # Handle empty clusters more robustly\n",
        "                    new_centroids[k] = X[np.random.choice(X.shape[0])]\n",
        "                else:\n",
        "                    new_centroids[k] = np.sum(X * responsibilities[:, k, np.newaxis], axis=0) / weight_sum\n",
        "\n",
        "            # Check convergence\n",
        "            if np.linalg.norm(new_centroids - self.centroids) < self.tol:\n",
        "                break\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "        # Store final responsibilities\n",
        "        self.responsibilities = self._compute_responsibilities(self._compute_distances(X))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Assign to cluster with highest responsibility\"\"\"\n",
        "        distances = self._compute_distances(X)\n",
        "        return np.argmin(distances, axis=1)\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    contingency = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(contingency, axis=0)) / np.sum(contingency)\n",
        "\n",
        "def gini_index(y_true, y_pred):\n",
        "    contingency = confusion_matrix(y_true, y_pred)\n",
        "    cluster_sizes = np.sum(contingency, axis=0)\n",
        "\n",
        "    # Handle empty clusters and division by zero\n",
        "    valid_clusters = cluster_sizes > 0\n",
        "    if np.sum(valid_clusters) == 0:\n",
        "        return 1.0  # Worst possible case when all clusters are empty\n",
        "\n",
        "    # Calculate purities only for valid clusters\n",
        "    cluster_purities = np.zeros_like(cluster_sizes, dtype=np.float64)\n",
        "    cluster_purities[valid_clusters] = np.amax(contingency[:, valid_clusters], axis=0) / cluster_sizes[valid_clusters]\n",
        "\n",
        "    # Calculate weighted Gini index\n",
        "    total_samples = np.sum(cluster_sizes)\n",
        "    weights = cluster_sizes[valid_clusters] / total_samples\n",
        "    gini = 1 - np.sum(weights * (cluster_purities[valid_clusters] ** 2))\n",
        "\n",
        "    return np.clip(gini, 0.0, 1.0)  # Ensure valid range\n",
        "\n",
        "# Run experiments with different beta values\n",
        "betas = [0.1, 1, 10]\n",
        "for beta in betas:\n",
        "    print(f\"\\nRunning Soft K-Means with β={beta}\")\n",
        "    skm = SoftKMeans(n_clusters=10, beta=beta, max_iter=100)\n",
        "    skm.fit(X_train_mnist_flat)\n",
        "\n",
        "    # Get cluster assignments\n",
        "    cluster_labels = skm.predict(X_train_mnist_flat)\n",
        "\n",
        "    # Calculate metrics\n",
        "    purity = purity_score(y_train_mnist, cluster_labels)\n",
        "    gini = gini_index(y_train_mnist, cluster_labels)\n",
        "\n",
        "    print(f\"β={beta}:\")\n",
        "    print(f\"Purity = {purity:.4f}\")\n",
        "    print(f\"Gini Index = {gini:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e4H4zYXt4Wl",
        "outputId": "84531109-76bc-42d6-a6fe-c672702ddbce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Soft K-Means with β=0.1\n",
            "β=0.1:\n",
            "Purity = 0.3594\n",
            "Gini Index = 0.8671\n",
            "\n",
            "Running Soft K-Means with β=1\n",
            "β=1:\n",
            "Purity = 0.2096\n",
            "Gini Index = 0.9560\n",
            "\n",
            "Running Soft K-Means with β=10\n",
            "β=10:\n",
            "Purity = 0.5871\n",
            "Gini Index = 0.6100\n"
          ]
        }
      ]
    }
  ]
}